{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.2.tar.gz (23 kB)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20210108)\nRequirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.22)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.4.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (7.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=272453 sha256=93ef9690f0d9db3a8f706595b464cccba8174cc6013d0d554a8c30f1c6fb21a5\n  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n#os.getcwd()\nimport pycocotools\nos.chdir(\"../input/help-files\")\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image\nimport pandas as pd\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom engine import train_one_epoch, evaluate\nimport utils\nimport transforms as T\nprint(os.getcwd())","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/help-files\n","output_type":"stream"}]},{"cell_type":"code","source":"#import train.csv and remove 'no findings' samples\ndata_df = pd.read_csv('/kaggle/input/vinbigdata-original-image-dataset/vinbigdata/train.csv')\ndata_df.head()\n#len(data_df) #67914\n# Remove no finding samples\ndata_df = data_df.loc[data_df['class_id'] != 14].reset_index(drop=True)\ndata_df.head()","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                           image_id          class_name  class_id rad_id  \\\n0  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly         3    R10   \n1  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement         0    R10   \n2  1c32170b4af4ce1a3030eb8167753b06  Pleural thickening        11     R9   \n3  0c7a38f293d5f5e4846aa4ca6db4daf1                 ILD         5    R17   \n4  47ed17dcb2cbeec15182ed335a8b5a9e         Nodule/Mass         8     R9   \n\n    x_min   y_min   x_max   y_max  width  height  \n0   691.0  1375.0  1653.0  1831.0   2080    2336  \n1  1264.0   743.0  1611.0  1019.0   2304    2880  \n2   627.0   357.0   947.0   433.0   2540    3072  \n3  1347.0   245.0  2188.0  2169.0   2285    2555  \n4   557.0  2352.0   675.0  2484.0   2568    3353  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>class_name</th>\n      <th>class_id</th>\n      <th>rad_id</th>\n      <th>x_min</th>\n      <th>y_min</th>\n      <th>x_max</th>\n      <th>y_max</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n      <td>Cardiomegaly</td>\n      <td>3</td>\n      <td>R10</td>\n      <td>691.0</td>\n      <td>1375.0</td>\n      <td>1653.0</td>\n      <td>1831.0</td>\n      <td>2080</td>\n      <td>2336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>051132a778e61a86eb147c7c6f564dfe</td>\n      <td>Aortic enlargement</td>\n      <td>0</td>\n      <td>R10</td>\n      <td>1264.0</td>\n      <td>743.0</td>\n      <td>1611.0</td>\n      <td>1019.0</td>\n      <td>2304</td>\n      <td>2880</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1c32170b4af4ce1a3030eb8167753b06</td>\n      <td>Pleural thickening</td>\n      <td>11</td>\n      <td>R9</td>\n      <td>627.0</td>\n      <td>357.0</td>\n      <td>947.0</td>\n      <td>433.0</td>\n      <td>2540</td>\n      <td>3072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0c7a38f293d5f5e4846aa4ca6db4daf1</td>\n      <td>ILD</td>\n      <td>5</td>\n      <td>R17</td>\n      <td>1347.0</td>\n      <td>245.0</td>\n      <td>2188.0</td>\n      <td>2169.0</td>\n      <td>2285</td>\n      <td>2555</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47ed17dcb2cbeec15182ed335a8b5a9e</td>\n      <td>Nodule/Mass</td>\n      <td>8</td>\n      <td>R9</td>\n      <td>557.0</td>\n      <td>2352.0</td>\n      <td>675.0</td>\n      <td>2484.0</td>\n      <td>2568</td>\n      <td>3353</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#adjust bounding boxes according to the resized images dimension ( 512 X 512)\ndata_df['x_min'] = data_df.apply(lambda row: (row.x_min)/row.height*512, axis =1)\ndata_df['y_min'] = data_df.apply(lambda row: (row.y_min)/row.width*512, axis =1)\n\ndata_df['x_max'] = data_df.apply(lambda row: (row.x_max)/row.height*512, axis =1)\ndata_df['y_max'] = data_df.apply(lambda row: (row.y_max)/row.width*512, axis =1)","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#check if bounding box valuse are not consistent and remove those records in case of inconsistency\ndef calculate_iou(bbox1, bbox2):\n    # Coordinates must be consistent\n    #print(bbox1['x_min'])\n    assert(bbox1['x_min'] < bbox1['x_max'])\n    assert(bbox1['y_min'] < bbox1['y_max'])\n    assert(bbox2['x_min'] < bbox2['x_max'])\n    assert(bbox2['y_min'] < bbox2['y_max'])\n    \n    # Calculate coordinates of the top left corner of the intersection area\n    x_top_left = max(bbox1['x_min'], bbox2['x_min'])\n    y_top_left = max(bbox1['y_min'], bbox2['y_min'])\n    \n    # Calculate coordinates of the bottom right corner of the intersection area\n    x_bottom_right = min(bbox1['x_max'], bbox2['x_max'])\n    y_bottom_right = min(bbox1['y_max'], bbox2['y_max'])\n    \n    # Calculate IOU\n    area_bbox1 = ((bbox1['x_max'] - bbox1['x_min']) * (bbox1['y_max'] - bbox1['y_min']))\n    assert area_bbox1 > 0\n    area_bbox2 = ((bbox2['x_max'] - bbox2['x_min']) * (bbox2['y_max'] - bbox2['y_min']))\n    assert area_bbox2 > 0\n    \n    if x_top_left > x_bottom_right or y_top_left > y_bottom_right:\n        return 0.0, area_bbox1, area_bbox2\n    \n    area_intersection = (x_bottom_right - x_top_left) * (y_bottom_right - y_top_left) \n    assert area_intersection >= 0\n    \n    area_union = area_bbox1 + area_bbox2 - area_intersection\n    \n    iou = area_intersection / area_union\n    assert iou >= 0.0 and iou <= 1.0\n    \n    return iou, area_bbox1, area_bbox2\n\n# Remove bounding boxes with high IOU and same class\ndef remove_bboxs(df, threshold=0.5):\n    img_ids = df['image_id'].unique()\n    new_records = list()\n\n    for img_id in img_ids:\n        records = df[df['image_id'] == img_id].reset_index(drop=True)\n        to_drop = list()\n        size = records.shape[0]\n        for i in range(size-1):\n            if i in to_drop:\n                continue\n            bbox1 = records.iloc[[i],:]\n            bbox1 = bbox1.to_dict('records')[0]\n            for j in range(i+1, size):\n                bbox2 = records.iloc[[j],:]\n                bbox2 = bbox2.to_dict('records')[0]\n\n                iou, bb1_area, bb2_area = calculate_iou(bbox1, bbox2)\n                if iou >= threshold and bbox1['class_id'] == bbox2['class_id']:\n                    if bb1_area >= bb2_area:\n                        to_drop.append(i)\n                        break\n                    else:\n                        to_drop.append(j)\n        records = records.loc[~records.index.isin(to_drop)]\n        new_records.append(records)\n\n    return pd.concat(new_records)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(data_df.shape)\ndata_df = remove_bboxs(data_df, threshold = 0.1)\nprint(data_df.shape)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(36096, 10)\n(20747, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"testt = data_df\ntestt.head()\ntestt = testt.drop_duplicates('image_id')\ntestt.shape\n# testt.head()\n# len(testt)\n# img_in_testt = testt['image_id'] + '.jpg'\n# img_in_testt = img_in_testt.to_list()\n# len(img_in_testt)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(4394, 10)"},"metadata":{}}]},{"cell_type":"code","source":"len(testt)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"4394"},"metadata":{}}]},{"cell_type":"code","source":"#train test split\nfrom sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(testt, test_size=0.2)\nlen(train), len(valid)\nvalid","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                            image_id          class_name  class_id rad_id  \\\n2   127f66766091998a72268caf4ec34bef        Cardiomegaly         3     R8   \n0   47110277377a779131d0e08d4389a503  Pulmonary fibrosis        13     R8   \n2   6747991aa8970e35ec44fe90b309d627  Pleural thickening        11    R10   \n1   18533a53425600e4da1e36085cbad104  Aortic enlargement         0    R10   \n1   6312578be73812b1634727a012980bc6  Pleural thickening        11     R8   \n..                               ...                 ...       ...    ...   \n2   908cff12e3ce717c4fc6cba8290b89a6         Nodule/Mass         8     R9   \n1   c1ca66539955f94f6dbd74fb5ba7208d                 ILD         5    R10   \n0   bf2d10fe88254cf97b08fab2e7c80232        Cardiomegaly         3     R8   \n1   bd3f8d06c2eab0bfe5428dfe3f9a1499    Pleural effusion        10     R9   \n0   b5be61351d358e354a42633e5d853352        Infiltration         6     R8   \n\n         x_min       y_min       x_max       y_max  width  height  \n2   196.937973  294.087343  433.960666  370.262028   2702    2644  \n0   108.361431  115.735109  135.218921  136.950055   2703    3298  \n2   107.666667   81.637795  128.000000   96.957480   2540    3072  \n1   259.056180  137.117318  301.662921  186.458101   2864    2848  \n1   126.752089   87.094801  206.618384  107.840979   2616    2872  \n..         ...         ...         ...         ...    ...     ...  \n2    74.208589  347.491409   87.754601  365.305842   2328    2608  \n1   118.833333  185.166667  191.666667  296.833333   3072    3072  \n0   184.015199  307.565714  354.087397  409.234286   2800    3158  \n1    18.178404   98.934019  146.779343  460.668380   2334    3408  \n0   343.040000   81.570647  371.612903  111.067911   3107    3100  \n\n[879 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>class_name</th>\n      <th>class_id</th>\n      <th>rad_id</th>\n      <th>x_min</th>\n      <th>y_min</th>\n      <th>x_max</th>\n      <th>y_max</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>127f66766091998a72268caf4ec34bef</td>\n      <td>Cardiomegaly</td>\n      <td>3</td>\n      <td>R8</td>\n      <td>196.937973</td>\n      <td>294.087343</td>\n      <td>433.960666</td>\n      <td>370.262028</td>\n      <td>2702</td>\n      <td>2644</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>47110277377a779131d0e08d4389a503</td>\n      <td>Pulmonary fibrosis</td>\n      <td>13</td>\n      <td>R8</td>\n      <td>108.361431</td>\n      <td>115.735109</td>\n      <td>135.218921</td>\n      <td>136.950055</td>\n      <td>2703</td>\n      <td>3298</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6747991aa8970e35ec44fe90b309d627</td>\n      <td>Pleural thickening</td>\n      <td>11</td>\n      <td>R10</td>\n      <td>107.666667</td>\n      <td>81.637795</td>\n      <td>128.000000</td>\n      <td>96.957480</td>\n      <td>2540</td>\n      <td>3072</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18533a53425600e4da1e36085cbad104</td>\n      <td>Aortic enlargement</td>\n      <td>0</td>\n      <td>R10</td>\n      <td>259.056180</td>\n      <td>137.117318</td>\n      <td>301.662921</td>\n      <td>186.458101</td>\n      <td>2864</td>\n      <td>2848</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6312578be73812b1634727a012980bc6</td>\n      <td>Pleural thickening</td>\n      <td>11</td>\n      <td>R8</td>\n      <td>126.752089</td>\n      <td>87.094801</td>\n      <td>206.618384</td>\n      <td>107.840979</td>\n      <td>2616</td>\n      <td>2872</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>908cff12e3ce717c4fc6cba8290b89a6</td>\n      <td>Nodule/Mass</td>\n      <td>8</td>\n      <td>R9</td>\n      <td>74.208589</td>\n      <td>347.491409</td>\n      <td>87.754601</td>\n      <td>365.305842</td>\n      <td>2328</td>\n      <td>2608</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c1ca66539955f94f6dbd74fb5ba7208d</td>\n      <td>ILD</td>\n      <td>5</td>\n      <td>R10</td>\n      <td>118.833333</td>\n      <td>185.166667</td>\n      <td>191.666667</td>\n      <td>296.833333</td>\n      <td>3072</td>\n      <td>3072</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>bf2d10fe88254cf97b08fab2e7c80232</td>\n      <td>Cardiomegaly</td>\n      <td>3</td>\n      <td>R8</td>\n      <td>184.015199</td>\n      <td>307.565714</td>\n      <td>354.087397</td>\n      <td>409.234286</td>\n      <td>2800</td>\n      <td>3158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bd3f8d06c2eab0bfe5428dfe3f9a1499</td>\n      <td>Pleural effusion</td>\n      <td>10</td>\n      <td>R9</td>\n      <td>18.178404</td>\n      <td>98.934019</td>\n      <td>146.779343</td>\n      <td>460.668380</td>\n      <td>2334</td>\n      <td>3408</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>b5be61351d358e354a42633e5d853352</td>\n      <td>Infiltration</td>\n      <td>6</td>\n      <td>R8</td>\n      <td>343.040000</td>\n      <td>81.570647</td>\n      <td>371.612903</td>\n      <td>111.067911</td>\n      <td>3107</td>\n      <td>3100</td>\n    </tr>\n  </tbody>\n</table>\n<p>879 rows Ã— 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"img_in_train = train['image_id'] + '.jpg'\nimg_in_train = img_in_train.to_list()\n\nimg_in_valid = valid['image_id'] + '.jpg'\nimg_in_valid = img_in_valid.to_list()\nlen(img_in_train), len(img_in_valid)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(3515, 879)"},"metadata":{}}]},{"cell_type":"code","source":"class VinBigDataset(torch.utils.data.Dataset):\n    def __init__(self, root, li, data_file, transforms=None):\n      self.root = root\n      self.li=li   \n      self.transforms = transforms \n      #self.imgs = sorted(os.listdir(os.path.join(root, \"train\")))\n      self.imgs = li  \n      self.path_to_data_file = data_file\n      #img_path = os.path.join(self.root, \"train\", self.imgs[0])\n      \n      \n      \n    def __getitem__(self, idx):\n      # load images and bounding boxes\n      img_path = os.path.join(self.root, \"train\", self.imgs[idx])\n      img = Image.open(img_path).convert(\"RGB\")\n      img = img.resize((512,512))\n      box_list = parse_one_annot(self.path_to_data_file, \n      self.imgs[idx])\n      \n     \n      boxes = torch.as_tensor(box_list, dtype=torch.float32)\n     \n      num_objs = len(box_list)\n      # there is only one class\n      #labels = torch.ones((num_objs,), dtype=torch.int64)\n      labels= parse_label(self.path_to_data_file, self.imgs[idx])  \n      \n      #labels= torch.from_numpy(data[\"class_id\"].values)\n\n      image_id = torch.tensor([idx])\n      area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,\n      0])\n      # suppose all instances are not crowd\n      iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n      target = {}\n      target[\"boxes\"] = boxes\n      target[\"labels\"] = labels\n      target[\"image_id\"] = image_id\n      target[\"area\"] = area\n      target[\"iscrowd\"] = iscrowd\n      if self.transforms is not None:\n        img, target = self.transforms(img, target)\n      return img, target\n    def __len__(self):\n         return len(self.imgs)\n\n\n\ndef get_transform(train):\n   transforms = []\n   # converts the image, a PIL image, into a PyTorch Tensor\n   transforms.append(T.ToTensor())\n   if train:\n      #pass\n      # during training, randomly flip the training images\n      # and ground-truth for data augmentation\n      transforms.append(T.RandomHorizontalFlip(0.5))\n   return T.Compose(transforms)\n\ndef parse_one_annot(path_to_data_file, filename):\n   #data = pd.read_csv(path_to_data_file)\n   data = path_to_data_file\n   ab= data[\"image_id\"] + '.jpg'\n   boxes_array = data[ab == filename][[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values\n   \n   return boxes_array\n\ndef parse_label(path_to_data_file, filename):\n   #print(path_to_data_file)\n   #data = pd.read_csv(path_to_data_file)\n   data = path_to_data_file\n   ab= data[\"image_id\"] + '.jpg'\n   label = []\n   label = data[ab == filename][\"class_id\"].values\n   label = torch.from_numpy(label)\n   return label\n\n\n# use our dataset and defined transformations\n\ndataset_train = VinBigDataset(root= \"/kaggle/input/vinbigdata-original-image-dataset/vinbigdata\", \n                           li = img_in_train, data_file= train,transforms = get_transform(train=True))\ndataset_valid = VinBigDataset(root= \"/kaggle/input/vinbigdata-original-image-dataset/vinbigdata\", \n                           li = img_in_valid, data_file= valid,transforms = get_transform(train=False))\nlen(dataset_train), len(dataset_valid)\n","metadata":{"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(3515, 879)"},"metadata":{}}]},{"cell_type":"code","source":"\ndata_loader_train = torch.utils.data.DataLoader(\n              dataset_train, batch_size=10, shuffle=True, num_workers=4,\n              collate_fn=utils.collate_fn)\ndata_loader_valid = torch.utils.data.DataLoader(\n              dataset_valid, batch_size=10, shuffle=True, num_workers=4,\n              collate_fn=utils.collate_fn)\n\nlen(data_loader_train), len(data_loader_valid)","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(352, 88)"},"metadata":{}}]},{"cell_type":"code","source":"num_classes = 15\n\nimport torchvision\ndef get_model(num_classes):\n   # load an object detection model pre-trained on COCO\n   model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n# get the number of input features for the classifier\n   in_features = model.roi_heads.box_predictor.cls_score.in_features\n   print(in_features)\n   # replace the pre-trained head with a new on\n   model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n   \n   return model\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# our dataset has two classes only - raccoon and not racoon\n# get the model using our helper function\nmodel = get_model(num_classes)\n#move model to the right device\nmodel.to(device)\n# construct an optimizer\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005,\n                            momentum=0.9, weight_decay=0.0005)\n# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=3,\n                                               gamma=0.1)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/160M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b597e11413814d739e7df4cddf544e09"}},"metadata":{}},{"name":"stdout","text":"1024\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's train it for 10 epochs\nnum_epochs = 1\nfor epoch in range(num_epochs):\n   # train for one epoch, printing every 10 iterations\n   metric = train_one_epoch(model, optimizer,data_loader_train , device, epoch, print_freq=10)\n# update the learning rate\n   lr_scheduler.step()\n   # evaluate on the test dataset\n   evaluate(model, data_loader_valid, device=device)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch: [0]  [  0/352]  eta: 0:44:16  lr: 0.000019  loss: 2.3215 (2.3215)  loss_classifier: 2.1679 (2.1679)  loss_box_reg: 0.0195 (0.0195)  loss_objectness: 0.1258 (0.1258)  loss_rpn_box_reg: 0.0083 (0.0083)  time: 7.5478  data: 5.0672  max mem: 7159\nEpoch: [0]  [ 10/352]  eta: 0:11:11  lr: 0.000162  loss: 2.1718 (2.0331)  loss_classifier: 1.9403 (1.7881)  loss_box_reg: 0.0146 (0.0127)  loss_objectness: 0.1825 (0.2199)  loss_rpn_box_reg: 0.0102 (0.0124)  time: 1.9638  data: 0.5453  max mem: 7425\nEpoch: [0]  [ 20/352]  eta: 0:09:17  lr: 0.000304  loss: 0.8332 (1.2931)  loss_classifier: 0.7022 (1.0353)  loss_box_reg: 0.0123 (0.0129)  loss_objectness: 0.1825 (0.2331)  loss_rpn_box_reg: 0.0103 (0.0118)  time: 1.3869  data: 0.0876  max mem: 7425\nEpoch: [0]  [ 30/352]  eta: 0:08:44  lr: 0.000446  loss: 0.2661 (0.9574)  loss_classifier: 0.0613 (0.7175)  loss_box_reg: 0.0120 (0.0131)  loss_objectness: 0.1794 (0.2155)  loss_rpn_box_reg: 0.0101 (0.0114)  time: 1.4452  data: 0.1301  max mem: 7425\nEpoch: [0]  [ 40/352]  eta: 0:08:11  lr: 0.000588  loss: 0.2356 (0.7819)  loss_classifier: 0.0481 (0.5549)  loss_box_reg: 0.0133 (0.0134)  loss_objectness: 0.1476 (0.2018)  loss_rpn_box_reg: 0.0108 (0.0118)  time: 1.4652  data: 0.1446  max mem: 7425\nEpoch: [0]  [ 50/352]  eta: 0:07:48  lr: 0.000731  loss: 0.1910 (0.6641)  loss_classifier: 0.0472 (0.4550)  loss_box_reg: 0.0130 (0.0136)  loss_objectness: 0.1224 (0.1834)  loss_rpn_box_reg: 0.0108 (0.0120)  time: 1.4282  data: 0.1342  max mem: 7425\nEpoch: [0]  [ 60/352]  eta: 0:07:27  lr: 0.000873  loss: 0.1616 (0.5818)  loss_classifier: 0.0497 (0.3892)  loss_box_reg: 0.0165 (0.0144)  loss_objectness: 0.0774 (0.1666)  loss_rpn_box_reg: 0.0085 (0.0117)  time: 1.4483  data: 0.1508  max mem: 7425\nEpoch: [0]  [ 70/352]  eta: 0:07:10  lr: 0.001015  loss: 0.1584 (0.5239)  loss_classifier: 0.0417 (0.3399)  loss_box_reg: 0.0143 (0.0142)  loss_objectness: 0.0707 (0.1576)  loss_rpn_box_reg: 0.0075 (0.0121)  time: 1.4612  data: 0.1750  max mem: 7425\nEpoch: [0]  [ 80/352]  eta: 0:06:52  lr: 0.001158  loss: 0.1486 (0.4826)  loss_classifier: 0.0383 (0.3032)  loss_box_reg: 0.0120 (0.0142)  loss_objectness: 0.0832 (0.1517)  loss_rpn_box_reg: 0.0102 (0.0135)  time: 1.4625  data: 0.1620  max mem: 7425\nEpoch: [0]  [ 90/352]  eta: 0:06:36  lr: 0.001300  loss: 0.1353 (0.4437)  loss_classifier: 0.0359 (0.2740)  loss_box_reg: 0.0112 (0.0139)  loss_objectness: 0.0696 (0.1427)  loss_rpn_box_reg: 0.0100 (0.0131)  time: 1.4629  data: 0.1412  max mem: 7425\nEpoch: [0]  [100/352]  eta: 0:06:20  lr: 0.001442  loss: 0.1236 (0.4134)  loss_classifier: 0.0397 (0.2510)  loss_box_reg: 0.0115 (0.0139)  loss_objectness: 0.0647 (0.1356)  loss_rpn_box_reg: 0.0089 (0.0129)  time: 1.4821  data: 0.1633  max mem: 7425\nEpoch: [0]  [110/352]  eta: 0:06:02  lr: 0.001585  loss: 0.1385 (0.3907)  loss_classifier: 0.0434 (0.2324)  loss_box_reg: 0.0143 (0.0140)  loss_objectness: 0.0687 (0.1317)  loss_rpn_box_reg: 0.0100 (0.0127)  time: 1.4397  data: 0.1347  max mem: 7425\nEpoch: [0]  [120/352]  eta: 0:05:47  lr: 0.001727  loss: 0.1492 (0.3727)  loss_classifier: 0.0479 (0.2173)  loss_box_reg: 0.0167 (0.0144)  loss_objectness: 0.0700 (0.1281)  loss_rpn_box_reg: 0.0087 (0.0128)  time: 1.4282  data: 0.1104  max mem: 7425\nEpoch: [0]  [130/352]  eta: 0:05:31  lr: 0.001869  loss: 0.1447 (0.3563)  loss_classifier: 0.0497 (0.2049)  loss_box_reg: 0.0182 (0.0151)  loss_objectness: 0.0648 (0.1236)  loss_rpn_box_reg: 0.0087 (0.0127)  time: 1.4570  data: 0.1219  max mem: 7425\nEpoch: [0]  [140/352]  eta: 0:05:14  lr: 0.002012  loss: 0.1457 (0.3424)  loss_classifier: 0.0534 (0.1945)  loss_box_reg: 0.0194 (0.0157)  loss_objectness: 0.0616 (0.1196)  loss_rpn_box_reg: 0.0092 (0.0126)  time: 1.4181  data: 0.1115  max mem: 7425\nEpoch: [0]  [150/352]  eta: 0:05:00  lr: 0.002154  loss: 0.1516 (0.3306)  loss_classifier: 0.0534 (0.1853)  loss_box_reg: 0.0219 (0.0161)  loss_objectness: 0.0644 (0.1165)  loss_rpn_box_reg: 0.0084 (0.0126)  time: 1.4743  data: 0.1461  max mem: 7425\nEpoch: [0]  [160/352]  eta: 0:04:44  lr: 0.002296  loss: 0.1536 (0.3217)  loss_classifier: 0.0484 (0.1769)  loss_box_reg: 0.0224 (0.0165)  loss_objectness: 0.0674 (0.1152)  loss_rpn_box_reg: 0.0085 (0.0131)  time: 1.4647  data: 0.1351  max mem: 7425\nEpoch: [0]  [170/352]  eta: 0:04:30  lr: 0.002438  loss: 0.1536 (0.3118)  loss_classifier: 0.0423 (0.1688)  loss_box_reg: 0.0147 (0.0164)  loss_objectness: 0.0838 (0.1136)  loss_rpn_box_reg: 0.0117 (0.0130)  time: 1.4524  data: 0.1639  max mem: 7425\nEpoch: [0]  [180/352]  eta: 0:04:14  lr: 0.002581  loss: 0.1482 (0.3041)  loss_classifier: 0.0389 (0.1622)  loss_box_reg: 0.0147 (0.0166)  loss_objectness: 0.0816 (0.1120)  loss_rpn_box_reg: 0.0134 (0.0133)  time: 1.4760  data: 0.1772  max mem: 7425\nEpoch: [0]  [190/352]  eta: 0:04:00  lr: 0.002723  loss: 0.1482 (0.2960)  loss_classifier: 0.0517 (0.1567)  loss_box_reg: 0.0226 (0.0171)  loss_objectness: 0.0598 (0.1092)  loss_rpn_box_reg: 0.0082 (0.0131)  time: 1.4933  data: 0.1561  max mem: 7425\nEpoch: [0]  [200/352]  eta: 0:03:45  lr: 0.002865  loss: 0.1560 (0.2910)  loss_classifier: 0.0549 (0.1518)  loss_box_reg: 0.0239 (0.0175)  loss_objectness: 0.0685 (0.1084)  loss_rpn_box_reg: 0.0086 (0.0133)  time: 1.4951  data: 0.1633  max mem: 7425\nEpoch: [0]  [210/352]  eta: 0:03:30  lr: 0.003008  loss: 0.1560 (0.2846)  loss_classifier: 0.0503 (0.1469)  loss_box_reg: 0.0201 (0.0175)  loss_objectness: 0.0711 (0.1069)  loss_rpn_box_reg: 0.0104 (0.0133)  time: 1.4311  data: 0.1052  max mem: 7425\nEpoch: [0]  [220/352]  eta: 0:03:14  lr: 0.003150  loss: 0.1433 (0.2787)  loss_classifier: 0.0453 (0.1423)  loss_box_reg: 0.0167 (0.0175)  loss_objectness: 0.0704 (0.1054)  loss_rpn_box_reg: 0.0102 (0.0134)  time: 1.4148  data: 0.0854  max mem: 7425\nEpoch: [0]  [230/352]  eta: 0:02:59  lr: 0.003292  loss: 0.1483 (0.2731)  loss_classifier: 0.0480 (0.1384)  loss_box_reg: 0.0180 (0.0177)  loss_objectness: 0.0630 (0.1037)  loss_rpn_box_reg: 0.0102 (0.0134)  time: 1.3963  data: 0.0843  max mem: 7425\nEpoch: [0]  [240/352]  eta: 0:02:44  lr: 0.003435  loss: 0.1516 (0.2685)  loss_classifier: 0.0478 (0.1347)  loss_box_reg: 0.0200 (0.0179)  loss_objectness: 0.0576 (0.1026)  loss_rpn_box_reg: 0.0083 (0.0133)  time: 1.4085  data: 0.0871  max mem: 7425\nEpoch: [0]  [250/352]  eta: 0:02:30  lr: 0.003577  loss: 0.1499 (0.2637)  loss_classifier: 0.0454 (0.1312)  loss_box_reg: 0.0196 (0.0181)  loss_objectness: 0.0572 (0.1012)  loss_rpn_box_reg: 0.0077 (0.0133)  time: 1.4348  data: 0.1090  max mem: 7425\nEpoch: [0]  [260/352]  eta: 0:02:15  lr: 0.003719  loss: 0.1471 (0.2598)  loss_classifier: 0.0486 (0.1282)  loss_box_reg: 0.0225 (0.0183)  loss_objectness: 0.0508 (0.1002)  loss_rpn_box_reg: 0.0081 (0.0132)  time: 1.4925  data: 0.1667  max mem: 7425\nEpoch: [0]  [270/352]  eta: 0:02:00  lr: 0.003862  loss: 0.1474 (0.2556)  loss_classifier: 0.0531 (0.1253)  loss_box_reg: 0.0234 (0.0184)  loss_objectness: 0.0532 (0.0988)  loss_rpn_box_reg: 0.0081 (0.0131)  time: 1.5081  data: 0.1889  max mem: 7426\nEpoch: [0]  [280/352]  eta: 0:01:46  lr: 0.004004  loss: 0.1482 (0.2522)  loss_classifier: 0.0557 (0.1231)  loss_box_reg: 0.0247 (0.0187)  loss_objectness: 0.0570 (0.0974)  loss_rpn_box_reg: 0.0080 (0.0129)  time: 1.4944  data: 0.1569  max mem: 7426\nEpoch: [0]  [290/352]  eta: 0:01:31  lr: 0.004146  loss: 0.1472 (0.2491)  loss_classifier: 0.0609 (0.1211)  loss_box_reg: 0.0257 (0.0192)  loss_objectness: 0.0467 (0.0960)  loss_rpn_box_reg: 0.0074 (0.0128)  time: 1.4811  data: 0.1227  max mem: 7426\nEpoch: [0]  [300/352]  eta: 0:01:16  lr: 0.004288  loss: 0.1464 (0.2464)  loss_classifier: 0.0569 (0.1190)  loss_box_reg: 0.0283 (0.0195)  loss_objectness: 0.0520 (0.0951)  loss_rpn_box_reg: 0.0067 (0.0128)  time: 1.4851  data: 0.1339  max mem: 7426\nEpoch: [0]  [310/352]  eta: 0:01:01  lr: 0.004431  loss: 0.1462 (0.2435)  loss_classifier: 0.0537 (0.1172)  loss_box_reg: 0.0285 (0.0198)  loss_objectness: 0.0544 (0.0938)  loss_rpn_box_reg: 0.0078 (0.0127)  time: 1.4666  data: 0.1318  max mem: 7426\nEpoch: [0]  [320/352]  eta: 0:00:47  lr: 0.004573  loss: 0.1459 (0.2408)  loss_classifier: 0.0540 (0.1152)  loss_box_reg: 0.0282 (0.0200)  loss_objectness: 0.0512 (0.0930)  loss_rpn_box_reg: 0.0079 (0.0126)  time: 1.4288  data: 0.0943  max mem: 7426\nEpoch: [0]  [330/352]  eta: 0:00:32  lr: 0.004715  loss: 0.1529 (0.2384)  loss_classifier: 0.0565 (0.1136)  loss_box_reg: 0.0278 (0.0202)  loss_objectness: 0.0528 (0.0921)  loss_rpn_box_reg: 0.0069 (0.0124)  time: 1.4235  data: 0.0933  max mem: 7426\nEpoch: [0]  [340/352]  eta: 0:00:17  lr: 0.004858  loss: 0.1496 (0.2360)  loss_classifier: 0.0573 (0.1118)  loss_box_reg: 0.0267 (0.0203)  loss_objectness: 0.0540 (0.0914)  loss_rpn_box_reg: 0.0069 (0.0124)  time: 1.4350  data: 0.1258  max mem: 7426\nEpoch: [0]  [350/352]  eta: 0:00:02  lr: 0.005000  loss: 0.1427 (0.2341)  loss_classifier: 0.0565 (0.1104)  loss_box_reg: 0.0259 (0.0206)  loss_objectness: 0.0555 (0.0907)  loss_rpn_box_reg: 0.0070 (0.0124)  time: 1.3916  data: 0.1311  max mem: 7426\nEpoch: [0]  [351/352]  eta: 0:00:01  lr: 0.005000  loss: 0.1427 (0.2338)  loss_classifier: 0.0573 (0.1102)  loss_box_reg: 0.0259 (0.0206)  loss_objectness: 0.0544 (0.0905)  loss_rpn_box_reg: 0.0070 (0.0124)  time: 1.3575  data: 0.1306  max mem: 7426\nEpoch: [0] Total time: 0:08:35 (1.4641 s / it)\ncreating index...\nindex created!\nTest:  [ 0/88]  eta: 0:07:09  model_time: 0.5910 (0.5910)  evaluator_time: 0.0416 (0.0416)  time: 4.8768  data: 4.2117  max mem: 7426\nTest:  [87/88]  eta: 0:00:01  model_time: 0.5491 (0.5760)  evaluator_time: 0.0279 (0.0337)  time: 1.1122  data: 0.5203  max mem: 7426\nTest: Total time: 0:01:46 (1.2085 s / it)\nAveraged stats: model_time: 0.5491 (0.5760)  evaluator_time: 0.0279 (0.0337)\nAccumulating evaluation results...\nDONE (t=0.28s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.019\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n","output_type":"stream"}]},{"cell_type":"code","source":"metric","metadata":{"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"<utils.MetricLogger at 0x7f0330d05ed0>"},"metadata":{}}]},{"cell_type":"code","source":"#save a model\nPATH = \"/kaggle/working/state_dict_model44.pt\"\ntorch.save(model.state_dict(), PATH)","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#load a trained model\nPATH = \"/kaggle/working/state_dict_model44.pt\"\nmodel = get_model(num_classes)\nmodel.load_state_dict(torch.load(PATH))","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1024\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# #test model on test data\n# test_df = pd.read_csv('/kaggle/input/vinbigdata-original-image-dataset/vinbigdata/test.csv')\n# test_df.head(), len(test_df)\n# aa = test_df['image_id'] + '.jpg'\n# aa = aa.to_list()\n\n# path= \"/kaggle/input/vinbigdata-original-image-dataset/vinbigdata\"\n# for i in range(2): #len(aa)\n#     img_path = os.path.join(path, \"test\", aa[i])\n#     img = Image.open(img_path).convert(\"RGB\")\n#     img = img.resize((512,512))\n#     img = torch.from_numpy(np.array(img))\n#     img = img.reshape(3, 512, 512)\n#     print(img.shape, type(img))\n# #     model.eval()\n# #     with torch.no_grad():\n# #         prediction = model([img.to(device)])\n","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"torch.Size([3, 512, 512]) <class 'torch.Tensor'>\ntorch.Size([3, 512, 512]) <class 'torch.Tensor'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# pick one image from the test set\nimg, _ = dataset_valid[0]\n# put the model in evaluation mode\nmodel.eval()\nwith torch.no_grad():\n    prediction = model([img])\nprediction","metadata":{"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"[{'boxes': tensor([], size=(0, 4)),\n  'labels': tensor([], dtype=torch.int64),\n  'scores': tensor([])}]"},"metadata":{}}]},{"cell_type":"code","source":"type(img)","metadata":{"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]}]}